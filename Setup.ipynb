{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c5dd9b-1d21-4997-91f9-dd121f9d9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GemmaTokenizer, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6407bb-a300-4c19-a1e9-e6a7e3a65576",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb260885-8bdc-451d-8b50-825805c9ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu_pytorch_tanh`, edit the `model.config` to set `hidden_activation=gelu_pytorch_tanh`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1b619fa6b84ffcb91cdc334327e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"google/codegemma-1.1-7b-it\"\n",
    "#tokenizer = GemmaTokenizer.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=gpu, torch_dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af260e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_prompt = '''\n",
    "Objective: Identify lines of code that might contain bugs.\n",
    "\n",
    "Context: I have a codebase written in c++. I need to find lines that might contain bugs based on specific criteria.\n",
    "\n",
    "Criteria for Identifying Potential Bugs:\n",
    "\n",
    "    Syntax Errors: Look for lines with syntax errors.\n",
    "    Logical Errors: Identify lines where the logic might be flawed (e.g., incorrect conditions, improper use of operators).\n",
    "    Runtime Errors: Find lines that might cause runtime errors (e.g., null pointer dereferences, out-of-bound array access).\n",
    "    Common Pitfalls: Check for common pitfalls in the language (e.g., off-by-one errors, improper resource management).\n",
    "    Code Quality Issues: Look for lines that deviate from standard coding practices (e.g., poor variable naming, lack of comments, complex expressions).\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "    Analyze the provided codebase and identify lines that match the above criteria.\n",
    "    Make sure to check for edge cases and scenarios where the input might cause unexpected behavior.\n",
    "    Pay attention to lines with complex logic or multiple operations as they are more prone to errors.\n",
    "    For each identified line, provide a json object with the following fields:\n",
    "        problematic_code: A snippet of the problematic code. \n",
    "        description: A description of the potential bug.\n",
    "        suggestion: A suggestion for how to fix or further investigate the issue.\n",
    "\n",
    "Here is an example of how the code could look like and what your response should be:\n",
    "\n",
    "Example1 - Code:\n",
    "c++\n",
    "\n",
    "double calculate_average(std::vector<int> numbers) {\n",
    "    int total = std::accumulate(numbers.begin(), numbers.end(), 0);\n",
    "    int count = numbers.size();\n",
    "    return total / static_cast<double>(count);\n",
    "}\n",
    "\n",
    "int get_element(std::vector<int> array, int index) {\n",
    "    return array.at(index);\n",
    "}\n",
    "\n",
    "Example1 - Response:\n",
    "\n",
    "json\n",
    "\n",
    "[{  problematic_code: \"return total / static_cast<double>(count);\",\n",
    "    description: \"Potential division by zero if numbers vector is empty\",\n",
    "    suggestion: \"Add a check to ensure count is not zero before performing the division.\" },\n",
    "    { problematic_code: \"return array.at(index);\",\n",
    "    description: \"Possible out-of-bound array access\",\n",
    "    suggestion: \"Add a check to ensure the index is within the bounds of the array.\" }]\n",
    "\n",
    "Please review the code below and use the formatting of the example to provide your response.\n",
    "\n",
    "Code to analyze:\n",
    "\n",
    "c++\n",
    "\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "using namespace std;\n",
    "\n",
    "int sum_of_elements(vector<int> arr) {\n",
    "    int sum = 0;\n",
    "    for (int i = 0; i <= arr.size(); i++) {\n",
    "        sum += arr[i];\n",
    "    }\n",
    "    return sum;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n;\n",
    "    cout << \"Enter the number of elements: \";\n",
    "    cin >> n;\n",
    "\n",
    "    vector<int> arr(n);\n",
    "    cout << \"Enter the elements:\" << endl;\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        cin >> arr[i];\n",
    "    }\n",
    "\n",
    "    int result = sum_of_elements();\n",
    "    cout << \"Sum of elements: \" << result << endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44fb6efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chat = [\n",
    "    { \"role\": \"user\", \"content\": new_prompt},\n",
    "]\n",
    "\n",
    "chat_prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160dbf6f-ca5e-428a-a29b-e25644dbf668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\n",
      "```json\n",
      "[{\n",
      "  \"problematic_code\": \"int result = sum_of_elements();\",\n",
      "  \"description\": \"Missing argument to the function call\",\n",
      "  \"suggestion\": \"Pass the vector of elements to the function as an argument.\"\n",
      "},\n",
      "{\n",
      "  \"problematic_code\": \"for (int i = 0; i <= arr.size(); i++) {\",\n",
      "  \"description\": \"Loop condition will result in accessing beyond the array bounds\",\n",
      "  \"suggestion\": \"Change the condition to i < arr.size() to avoid out-of-bounds access.\"\n",
      "}]\n",
      "```<eos>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = '''\\\n",
    "You are debugging some code. Can you help me identify the issues in this piece of code? Can you give me for every line a probability if this line contains a bug:\n",
    "def sumElementsOfList(in_list):\n",
    "    sum = 3\n",
    "    for i in list:\n",
    "        sum -= i\n",
    "    return sum\n",
    "'''\n",
    "\n",
    "prompt = \"\"\"\n",
    "Objective: The objective of this task is to identify potentially non-functional or suspicious code segments. Your task is to assign probabilities to each line of code based on how likely it is to be non-functional or contain errors.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Identify Non-Functional Code: Your primary goal is to identify code segments that are likely to be non-functional, contain errors, or deviate significantly from expected programming conventions.\n",
    "   \n",
    "2. Assign Probability Scores: For each code segment provided, assign a probability score ranging from 0 to 1, where 0 indicates high confidence that the code is functional and error-free, and 1 indicates high suspicion of non-functionality or errors.\n",
    "\n",
    "3. Consider Context and Syntax: Take into account the context in which the code appears and the syntactical correctness. Code segments that exhibit unusual or unexpected patterns, syntax errors, or inconsistencies are more likely to be flagged as suspicious.\n",
    "\n",
    "4. Highlight Uncommon Constructs: Pay particular attention to code constructs, functions, or methods that are rarely used or appear in unconventional contexts. These are often indicators of potential errors or unintended behavior.\n",
    "\n",
    "The output format should look like this:\n",
    "LOC    probability\n",
    "eg.\n",
    "1    0.2\n",
    "2    0.1\n",
    "3    0.9\n",
    "\n",
    "Do this for the following code snippet:\n",
    "```\n",
    "def sumElementsOfList(in_list):\n",
    "    sum = 3\n",
    "    for i in list:\n",
    "        sum -= i\n",
    "    return sum\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#model.generate(**inputs,  max_new_tokens=200)\n",
    "\n",
    "#new_prompt = '''Write code for fibonacci series in python'''\n",
    "inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
    "# print number of prompt tokes\n",
    "print(inputs[\"input_ids\"].shape[-1])\n",
    "\n",
    "\n",
    "#output = model.generate(**inputs, max_new_tokens=1000)\n",
    "#print(tokenizer.decode(output[0]))\n",
    "#prediction = output[0][-1]\n",
    "#softmaxed = torch.softmax(prediction,0)\n",
    "#print(tokenizer.convert_ids_to_tokens([torch.argmax(softmaxed)]))\n",
    "#print(inputs)\n",
    "prompt_len = inputs[\"input_ids\"].shape[-1]\n",
    "outputs = model.generate(**inputs, max_new_tokens=1000)\n",
    "print(tokenizer.decode(outputs[0][prompt_len:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c4aab58-719c-42fa-aca3-6069419da36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>class HNSW {\n",
      "    constructor(\n",
      "        dimension,\n",
      "        num_trees,\n",
      "        num_neighbors,\n",
      "        num_threads,\n",
      "        max_memory_size,\n",
      "        max_memory_usage,\n",
      "        max_memory_usage_per_node,\n",
      "        max_memory_usage_per_node_per_thread,\n",
      "        max_memory_usage_per_node_per_thread_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree,\n",
      "        max_memory_usage_per_node_per_thread_per_tree_per_thread_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree_per_tree\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = '''\\\n",
    "class HNSW {\n",
    "'''\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "prompt_len = inputs[\"input_ids\"].shape[-1]\n",
    "outputs = model.generate(**inputs, max_new_tokens=2000)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37df4b2f-e025-4fc7-aaf2-e8bb3532d0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'ohn']\n",
      "['<0xF0>', '<0x9F>', '<0xBE>', '<0xA0>']\n",
      "['Mer', 'kel']\n",
      "['üçø']\n",
      "['<0xF0>', '<0x9F>', '<0xAA>', '<0xA0>']\n",
      "['ü§å']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"Sohn\"))\n",
    "print(tokenizer.tokenize(chr(0x1FFA0)))\n",
    "print(tokenizer.tokenize(\"Merkel\"))\n",
    "print(tokenizer.tokenize(\"üçø\"))\n",
    "print(tokenizer.tokenize(\"ü™†\"))\n",
    "print(tokenizer.tokenize(\"ü§å\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79fc2d8e-5bc5-4fc4-973e-055b39fd113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(\"ü™†\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958cd615-c71f-419b-b1d9-27bdaf2ba28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>//use hnswlib to build hnsw\n",
      "//use hnswlib to build hnsw\n",
      "#include <iostream>\n",
      "#include <fstream>\n",
      "#include <string>\n",
      "#include <vector>\n",
      "#include <algorithm>\n",
      "#include <cmath>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include <queue>\n",
      "#include <stack>\n",
      "#include <list>\n",
      "#include <deque>\n",
      "#include <bitset>\n",
      "#include <sstream>\n",
      "#include <iomanip>\n",
      "#include <numeric>\n",
      "#include <functional>\n",
      "#include <utility>\n",
      "#include <tuple>\n",
      "#include <climits>\n",
      "#include <cfloat>\n",
      "#include <cstdint>\n",
      "#include <cstring>\n",
      "#include <cstdlib>\n",
      "#include <ctime>\n",
      "#include <cassert>\n",
      "#include <complex>\n",
      "#include <valarray>\n",
      "#include <array>\n",
      "#include <random>\n",
      "#include <limits>\n",
      "#include <locale>\n",
      "#include <codecvt>\n",
      "#include <regex>\n",
      "#include <filesystem>\n",
      "#include <thread>\n",
      "#include <mutex>\n",
      "#include <condition_variable>\n",
      "#include <future>\n",
      "#include <atomic>\n",
      "#include <chrono>\n",
      "#include <random>\n",
      "#include <unordered_map>\n",
      "#include <unordered_set>\n",
      "#include <set>\n",
      "#include <map>\n",
      "#include\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\\\n",
    "//use hnswlib to build hnsw\n",
    "'''\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "prompt_len = inputs[\"input_ids\"].shape[-1]\n",
    "outputs = model.generate(**inputs, max_new_tokens=2000)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918ff37-af66-4812-9f2c-e17cbb8afb19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
