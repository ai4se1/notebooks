{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import difflib\n",
    "import autopep8\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import json\n",
    "import tree_sitter_python as tspython\n",
    "import tree_sitter_java as tsjava\n",
    "\n",
    "from tree_sitter import Language, Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datset loading and preprocessing\n",
    "\n",
    "We only use logic errors and perform the following preprocessing steps:\n",
    "- Remove examples containing syntax errors\n",
    "- Remove blank lines\n",
    "- Format the buggy code and the solution\n",
    "- Remove comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Rtian/DebugBench\")\n",
    "df = pd.DataFrame(dataset['test'])\n",
    "filtered_df = df[df['category'] == 'logic error'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6579f785b89545dd9c53b8b00e2e1cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PY_LANGUAGE = Language(tspython.language(), \"python\")\n",
    "JAVA_LANGUAGE = Language(tsjava.language(), \"java\")\n",
    "\n",
    "py_parser = Parser()\n",
    "py_parser.set_language(PY_LANGUAGE)\n",
    "\n",
    "java_parser = Parser()\n",
    "java_parser.set_language(JAVA_LANGUAGE)\n",
    "\n",
    "def remove_blank_lines(text):\n",
    "    return \"\\n\".join([s.rstrip() for s in text.splitlines() if s.strip()])\n",
    "    \n",
    "def format_cpp_code(code):\n",
    "    try:\n",
    "        process = subprocess.Popen(['clang-format', '--style=file:./clang-format.txt'], \n",
    "                                   stdin=subprocess.PIPE, \n",
    "                                   stdout=subprocess.PIPE, \n",
    "                                   stderr=subprocess.PIPE)\n",
    "        formatted_code, errors = process.communicate(input=code.encode())\n",
    "        if process.returncode != 0:\n",
    "            print(\"Error cpp formatting code: \", errors.decode())\n",
    "            return code\n",
    "        process = subprocess.Popen(['g++', '-fpreprocessed', '-dD', '-E', '-P', '-'],\n",
    "                                   stdin=subprocess.PIPE,\n",
    "                                   stdout=subprocess.PIPE,\n",
    "                                   stderr=subprocess.PIPE)\n",
    "        formatted_code, errors = process.communicate(input=formatted_code)\n",
    "\n",
    "        \n",
    "        if process.returncode != 0:\n",
    "            print(\"Error cpp formatting code: \", errors.decode())\n",
    "            return code\n",
    "        \n",
    "        return remove_blank_lines(formatted_code.decode())\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        return code\n",
    "    \n",
    "def format_python_code(code):\n",
    "    try:\n",
    "        # ignore errors to prevent autopep from running forever\n",
    "        formatted_code = autopep8.fix_code(code, options={'ignore': ['E']})\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        return code\n",
    "    bytes_code = bytes(formatted_code, \"utf-8\")\n",
    "    array = bytearray(bytes_code)\n",
    "    tree = py_parser.parse(bytes_code)\n",
    "    def traverse(node):\n",
    "        if node.type == 'comment':\n",
    "            array[node.start_byte:node.end_byte]=(node.end_byte - node.start_byte) * b\" \"\n",
    "            return \n",
    "        elif node.child_count == 0:\n",
    "            return\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                traverse(child)\n",
    "            return\n",
    "    traverse(tree.root_node)\n",
    "    cleaned_code = array.decode(\"utf-8\")\n",
    "    return remove_blank_lines(cleaned_code)\n",
    "\n",
    "\n",
    "def format_java_code(code):\n",
    "    try:\n",
    "        process = subprocess.Popen(['clang-format', '--style=file:./clang-format-java.txt', '--assume-filename=Main.java'], \n",
    "                                   stdin=subprocess.PIPE, \n",
    "                                   stdout=subprocess.PIPE, \n",
    "                                   stderr=subprocess.PIPE)\n",
    "        formatted_code, errors = process.communicate(input=code.encode())\n",
    "        \n",
    "        if process.returncode != 0:\n",
    "            print(\"Error formatting java code: \", errors.decode())\n",
    "            return code\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        return code\n",
    "    \n",
    "    array = bytearray(formatted_code)\n",
    "    tree = java_parser.parse(formatted_code)\n",
    "    def traverse(node):\n",
    "        if \"comment\" in node.type:\n",
    "            #print(f\"Removed comment: {array[node.start_byte:node.end_byte].decode('utf-8')}\")\n",
    "            array[node.start_byte:node.end_byte]=(node.end_byte - node.start_byte) * b\" \"\n",
    "            return \n",
    "        elif node.child_count == 0:\n",
    "            return\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                traverse(child)\n",
    "            return\n",
    "    \n",
    "    traverse(tree.root_node)\n",
    "    cleaned_code = array.decode(\"utf-8\")\n",
    "    return remove_blank_lines(cleaned_code)\n",
    "\n",
    "def format_code(code, language):\n",
    "    if language == \"python3\":\n",
    "        return format_python_code(code)\n",
    "    elif language == \"cpp\":\n",
    "        return format_cpp_code(code)\n",
    "    elif language == \"java\":\n",
    "        return format_java_code(code)\n",
    "    else:\n",
    "        print(f\"Unsupported language: {language}\")\n",
    "        return code\n",
    "\n",
    "def format_entry(entry):\n",
    "    buggy_code = entry['buggy_code']\n",
    "    solution = entry['solution']\n",
    "    return pd.Series({\n",
    "        \"buggy_code_formatted\": format_code(buggy_code, entry['language']),\n",
    "        \"solution_formatted\": format_code(solution, entry['language'])\n",
    "    })\n",
    "    \n",
    "filtered_df[[\"buggy_code_formatted\", \"solution_formatted\"]] = filtered_df.progress_apply(format_entry, axis=1)\n",
    "\n",
    "formatted_df = filtered_df\n",
    "formatted_df.to_csv(\"formatted_code.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Solution: def canPlaceFlowers(self, flowerbed: List[int], n: int) -> bool: flowerbed=[0]+flowerbed+[0] for i in range(1,len(flowerbed)-1): if flowerbed[i]==0 and flowerbed[i+2]==0 and flowerbed[i-1]==0:flowerbed[i]=1;n-=1 if n<=0:return True return False\n"
     ]
    }
   ],
   "source": [
    "print(format_python_code(\"class Solution: def canPlaceFlowers(self, flowerbed: List[int], n: int) -> bool: flowerbed=[0]+flowerbed+[0] for i in range(1,len(flowerbed)-1): if flowerbed[i]==0 and flowerbed[i+2]==0 and flowerbed[i-1]==0:flowerbed[i]=1;n-=1 if n<=0:return True return False \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt the LLM\n",
    "After the preprocessing, we now retrieve lines of code that are relevant for fixing the buggy code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatted_df = pd.read_csv(\"formatted_code.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_changed_lines(file1_contents, file2_contents, print_diff=False):\n",
    "    diff = difflib.ndiff(file1_contents.splitlines(), file2_contents.splitlines())\n",
    "    \n",
    "    changed_lines = set()\n",
    "\n",
    "    current_line_number = 0\n",
    "    num_clusters = 0\n",
    "    current_block_start = 0\n",
    "    no_change_in_line = True\n",
    "    for line in diff: \n",
    "        if print_diff:\n",
    "            print(f\"{current_line_number}: {line}\")\n",
    " \n",
    "        if line.startswith('  '):\n",
    "            current_line_number += 1\n",
    "            no_change_in_line = True\n",
    "        else:\n",
    "            if no_change_in_line:\n",
    "                num_clusters += 1\n",
    "            no_change_in_line = False\n",
    "            if line.startswith('- '):  # Lines in file1 but not in file2\n",
    "                current_line_number += 1\n",
    "            changed_lines.add(current_line_number)\n",
    "    return list(changed_lines), num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56eed793131473da27ed2763f4f6dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n",
      "Json parsing failed\n",
      "Request failed\n"
     ]
    }
   ],
   "source": [
    "log_file = open(\"output2.json\", \"w\")\n",
    "log_file.write(\"[\")\n",
    "\n",
    "def retrieve_relevant_lines_for_entry(entry):\n",
    "    buggy_code = entry['buggy_code_formatted']\n",
    "    solution = entry['solution_formatted']\n",
    "    num_lines = buggy_code.count('\\n')\n",
    "    changed_lines = find_changed_lines(buggy_code, solution)\n",
    "\n",
    "    data = {\"code\": buggy_code, \"language\": entry['language']}\n",
    "    success = True\n",
    "    response_json = []\n",
    "    try:\n",
    "        resp = req.post(\"http://delos.eaalab.hpi.uni-potsdam.de:8010/highlight-code/\", json=data)\n",
    "        try:\n",
    "            response_json = resp.json()\n",
    "        except:\n",
    "            print(\"Json parsing failed\")\n",
    "            print(resp.text())\n",
    "    except:\n",
    "        print(\"Request failed\")\n",
    "        success = False    \n",
    "\n",
    "    predicted_lines = []\n",
    "    suggestions = []\n",
    "    descriptions = []\n",
    "    actions = []\n",
    "    for item in response_json:\n",
    "        line_number = int(item.get('line_number', \"1\"))\n",
    "        suggestions.append(item.get(\"description\", \"\"))\n",
    "        descriptions.append(item.get(\"suggestion\", \"\"))\n",
    "        predicted_lines.append(line_number)\n",
    "        actions.append(item.get(\"action\", \"\"))\n",
    "\n",
    "    result = {\n",
    "        'buggy_code': buggy_code,\n",
    "        'solution': solution,\n",
    "        'changed_lines': changed_lines,\n",
    "        'predicted_lines': predicted_lines,\n",
    "        'num_lines': num_lines,\n",
    "        'success': success,\n",
    "        'suggestions': suggestions,\n",
    "        'descriptions': descriptions,\n",
    "        'actions': actions,\n",
    "    }\n",
    "    log_file.write(f'{json.dumps(result)},')\n",
    "    log_file.flush()\n",
    "    return result\n",
    "\n",
    "\n",
    "results = formatted_df.progress_apply(retrieve_relevant_lines_for_entry, axis=1)\n",
    "\n",
    "log_file.write(\"]\")\n",
    "log_file.close()\n",
    "results_df = pd.DataFrame(results.tolist())\n",
    "results_df.to_csv(\"results_formatted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df = pd.read_csv(\"results_formatted.csv\")\n",
    "#df['num_clusters'] = df['changed_lines'].apply(ast.literal_eval[1])\n",
    "df[['changed_lines', 'num_clusters']] = df['changed_lines'].apply(ast.literal_eval).apply(pd.Series)\n",
    "df['predicted_lines'] = df['predicted_lines'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successful requests: 564\n",
      "buggy_code         class Solution {\\n   public:\\n    long long fa...\n",
      "solution           class Solution {\\n   public:\\n    long long fa...\n",
      "changed_lines                                                    [5]\n",
      "predicted_lines                                          [5, 13, 23]\n",
      "num_lines                                                         24\n",
      "success                                                         True\n",
      "suggestions        ['The function calculates the factorial of n +...\n",
      "descriptions       ['Change n + 1 to n in the recursive call.', '...\n",
      "actions                         ['change', 'change', 'insert_above']\n",
      "num_clusters                                                       1\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "success_df = df[df[\"success\"]]\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "# We need the following line when working with success_df instead of df\n",
    "#pd.options.mode.copy_on_write = False\n",
    "print(f'Number of successful requests: {len(success_df)}')\n",
    "df.head()\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.DataFrame(dataset['test'])\n",
    "df['language'] = df_dataset['language']\n",
    "df['level'] = df_dataset['level']\n",
    "df['category'] = df_dataset['category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(row):\n",
    "    labels = pd.Series([0] * (row['num_lines'] + 1))\n",
    "    for line in row['changed_lines']:\n",
    "        if line == 0 or line > row['num_lines'] +1:\n",
    "            continue\n",
    "        labels[line-1] = 1\n",
    "    assert len(labels) == row['num_lines']+1, f\"{len(labels)} != {row['num_lines']}\"\n",
    "    return labels.tolist()\n",
    "\n",
    "# TODO: Insertion points\n",
    "def create_predictions(row):\n",
    "    predictions = pd.Series([0] * (row['num_lines'] +1))\n",
    "    for line in row['predicted_lines']:\n",
    "        if line == -1:\n",
    "            continue\n",
    "        if line > row['num_lines'] + 1:\n",
    "            print(f\"Error {line} exceeds {row['num_lines']}\")\n",
    "            continue\n",
    "        predictions[line-1] = 1\n",
    "    assert len(predictions) == row['num_lines'] +1, f\"{len(labels)} != {row['num_lines']}\"\n",
    "    return predictions.tolist()\n",
    "\n",
    "df['labels'] = df.apply(create_labels, axis=1)\n",
    "df['predictions'] = df.apply(create_predictions, axis=1)\n",
    "\n",
    "labels = np.array([b for a in df['labels'].values for b in a])\n",
    "predictions = np.array([b for a in df['predictions'].values for b in a])\n",
    "assert len(labels) == len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchanged_lines\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_lines\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:2000\u001b[0m, in \u001b[0;36mNDFrame.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m bool_t:\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"True if the key is in the info axis\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py:371\u001b[0m, in \u001b[0;36mRangeIndex.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m         key \u001b[38;5;241m=\u001b[39m ensure_python_int(key)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "new_df = df[df['changed_lines'] in df['predicted_lines']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc0b5d5e2304416960c354f3d3bdf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m     conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(labels, predictions)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtn\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_matrix[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_matrix[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_matrix[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_matrix[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1_score(labels, predictions)}\n\u001b[0;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry_based_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 9\u001b[0m, in \u001b[0;36mentry_based_metrics\u001b[0;34m(entry)\u001b[0m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(labels, predictions)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtn\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_matrix[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mconf_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_matrix[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_matrix[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1_score(labels, predictions)}\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "def entry_based_metrics(entry):\n",
    "    labels = np.array(entry['labels'])\n",
    "    predictions = np.array(entry['predictions'])\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "    return {'tn': conf_matrix[0][0],\n",
    "            'fn': conf_matrix[1][0],\n",
    "            'fp': conf_matrix[0][1],\n",
    "            'tp': conf_matrix[1][1],\n",
    "            'f1': f1_score(labels, predictions)}\n",
    "\n",
    "\n",
    "\n",
    "results = df.progress_apply(entry_based_metrics, axis=1)\n",
    "\n",
    "results_df = pd.DataFrame(results.tolist())\n",
    "\n",
    "df['tp'] = results_df['tp']\n",
    "df['fp'] = results_df['fp']\n",
    "df['fn'] = results_df['fn']\n",
    "df['tn'] = results_df['tn']\n",
    "df['f1'] = results_df['f1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['f1'], bins=200, edgecolor='black')\n",
    "plt.title('Histogram of F1 Scores')\n",
    "plt.xlabel('F1 Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "res_df = df.sort_values(by='f1', ascending=False).head(10)#[['buggy_code', 'solution', 'changed_lines', 'predicted_lines']]\n",
    "\n",
    "def pretty_print(input_df):\n",
    "    return display(HTML(input_df.to_html().replace(\"\\\\n\", \"<br>\")))\n",
    "\n",
    "pretty_print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_and_print(input_df):\n",
    "    tn = input_df['tn'].sum()\n",
    "    fn = input_df['fn'].sum()\n",
    "    tp = input_df['tp'].sum()\n",
    "    fp = input_df['fp'].sum()\n",
    "    print([tn, fp], \"\\n\",\n",
    "           [fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"differen levels\")\n",
    "easy_df = df[df['level'] == 'easy']\n",
    "aggregate_and_print(easy_df)\n",
    "mid_df = df[df['level'] == 'medium']\n",
    "aggregate_and_print(mid_df)\n",
    "hard_df = df[df['level'] == 'hard']\n",
    "aggregate_and_print(hard_df)\n",
    "\n",
    "print(\"non zero\")\n",
    "non_zero_df = df[df['suggestions'].apply(lambda x: len(x) > 0)]\n",
    "aggregate_and_print(non_zero_df)\n",
    "\n",
    "print(\"zero\")\n",
    "zero_df = df[df['suggestions'].apply(lambda x: len(x) == 0)]\n",
    "aggregate_and_print(zero_df)\n",
    "\n",
    "print(\"error types\")\n",
    "easy_df = df[df['category'] == 'syntax error']\n",
    "aggregate_and_print(easy_df)\n",
    "mid_df = df[df['category'] == 'multiple error']\n",
    "aggregate_and_print(mid_df)\n",
    "hard_df = df[df['category'] == 'logic error']\n",
    "aggregate_and_print(hard_df)\n",
    "ref_df = df[df['category'] == 'reference error']\n",
    "aggregate_and_print(ref_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "balanced_acc = balanced_accuracy_score(labels, predictions)\n",
    "precision = precision_score(labels, predictions)\n",
    "recall = recall_score(labels, predictions)\n",
    "f1 = f1_score(labels, predictions)\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Balanced Accuracy: {balanced_acc}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "num_positives = labels.sum()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels, predictions)\n",
    "precision, recall, thresholds2 = precision_recall_curve(labels, predictions)\n",
    "fn = [(num_positives) - tp * num_positives for tp in tpr]\n",
    "f1 = [(2*tpr[i]*num_positives)/(2*tpr[i]*num_positives + fpr[i]*num_positives + fn[i]) for i in range(len(fpr))]\n",
    "print(max(f1))\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area\", roc_auc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, fpr, color='blue')\n",
    "plt.plot(thresholds, tpr, color='red')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Classification Thresholds')\n",
    "plt.ylabel('True/False Positive Rate')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, f1, color='navy')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Classification Thresholds')\n",
    "plt.ylabel('F1-Score')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(precision, recall, color='darkorange', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "length = min(len(precision), len(recall))\n",
    "plt.figure()\n",
    "plt.plot(thresholds2, precision[:length-1], color='blue')\n",
    "plt.plot(thresholds2, recall[:length-1], color='red')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Classification Thresholds')\n",
    "plt.ylabel('Precision blue / recall red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
